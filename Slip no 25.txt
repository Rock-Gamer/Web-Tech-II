 Slip no 25
 Write a script to create “cricket.xml” file with 
multiple elements as shown below: Write a script 
to add multiple elements in “cricket.xml” file 
of category, country=”India”.
 <?php
 function createCricketXML() {
 $doc = new DOMDocument();
 $cricketTeam = $doc
>createElement('CricketTeam');
 $doc->appendChild($cricketTeam);
 $teamAustralia = $doc
>createElement('Team');
 $teamAustralia->setAttribute('country', 
'Australia');
 $cricketTeam->appendChild($teamAustralia);
 $playerAustralia = $doc
>createElement('player', 'Player_Aus');
 $teamAustralia
>appendChild($playerAustralia);
 $runsAustralia = $doc->createElement('runs', 
'100');
 $teamAustralia->appendChild($runsAustralia);
  $wicketsAustralia = $doc
>createElement('wicket', '5');
    $teamAustralia
>appendChild($wicketsAustralia);
    $doc->formatOutput = true;
    $doc->save('cricket.xml');
 }
 function addElementsForIndia() {
    $doc = new DOMDocument();
    $doc->load('cricket.xml');
    $cricketTeam = $doc->documentElement;
    $teamIndia = $doc->createElement('Team');
    $teamIndia->setAttribute('country', 
'India');
    $cricketTeam->appendChild($teamIndia);
    $players = array('Player1', 'Player2', 
'Player3');
    $runs = array(50, 60, 70);
    $wickets = array(2, 3, 1);
    foreach ($players as $key => $player) {
        $playerIndia = $doc
>createElement('player', $player);
        $teamIndia->appendChild($playerIndia);
        $runsIndia = $doc->createElement('runs', 
$runs[$key]);
        $teamIndia->appendChild($runsIndia);
        $wicketsIndia = $doc
>createElement('wicket', $wickets[$key]);
        $teamIndia->appendChild($wicketsIndia);
    }
    $doc->formatOutput = true;
 $doc->save('cricket.xml');
 }
 if (!file_exists('cricket.xml')) {
 createCricketXML();
 }
 addElementsForIndia();
 echo "Elements added successfully to 
cricket.xml";
 ?>








import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
from textblob import TextBlob

# Download necessary resources
nltk.download('punkt')

# Load the dataset
file_path = "covid_2021_1.csv"  # Update this with your actual file path
df = pd.read_csv(file_path)

# Display basic info about the dataset
print("Initial Dataset Info:")
print(df.info())

# Drop unnecessary columns (if any)
df = df[['comment_text']].dropna()  # Keeping only the comments and dropping NaN values

# Function to clean the text
def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = text.replace('\n', ' ')  # Remove new lines
    text = ' '.join(text.split())  # Remove extra spaces
    return text

# Apply cleaning
df['cleaned_text'] = df['comment_text'].apply(clean_text)

# Tokenization
df['tokenized'] = df['cleaned_text'].apply(word_tokenize)

# Function for sentiment analysis
def get_sentiment(text):
    analysis = TextBlob(text)
    if analysis.sentiment.polarity > 0:
        return 'Positive'
    elif analysis.sentiment.polarity < 0:
        return 'Negative'
    else:
        return 'Neutral'

# Apply sentiment analysis
df['sentiment'] = df['cleaned_text'].apply(get_sentiment)

# Calculate sentiment percentages
sentiment_counts = df['sentiment'].value_counts(normalize=True) * 100
print("\nSentiment Analysis Results:")
print(sentiment_counts)

# Save the cleaned data with sentiment
df.to_csv("cleaned_youtube_comments.csv", index=False)

print("\nProcessed dataset saved as 'cleaned_youtube_comments.csv'")
